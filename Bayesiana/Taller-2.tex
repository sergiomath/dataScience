% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Taller 2: Estadística bayesiana},
  pdfauthor={Sergio Andres Diaz Vera},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Taller 2: Estadística bayesiana}
\author{Sergio Andres Diaz Vera}
\date{2022-08-29}

\begin{document}
\maketitle

\begin{enumerate}

\item Sean $x$, $y$, y $z$ variables aleatorias con función de densidad conjunta (discreta o continua) dada por $p(x,y,z) \propto             p(x,z)p(y,z)p(z)$. Muestre que:
\begin{enumerate}
  \item $p(x\mid y,z)\propto p(x,z)$, i.e., $p(x\mid y,z)$ es función de $x$ y $z$.
  \item$p(y\mid x,z)\propto p(y,z)$, i.e., $p(y\mid x,z)$ es función de $y$ y $z$.    
  \item $x$ y $y$ son condicionalmente independientes dado $z$.
\end{enumerate}  
\item Sean $A$, $B$, y $C$ proposiciones de falso-verdadero. Suponga que $A$ y $B$ son condicionalmente independientes, dado $C$. Muestre que:
  \begin{enumerate}
    \item $A$   y $B^C$ son condicionalmente independientes, dado $C$.  
    \item $A^C$ y $B^C$ son condicionalmente independientes, dado $C$.
  \end{enumerate}
\item Sea $y\mid x\sim\textsf{Poi}(x)$ y $x\sim\textsf{Exp}(\lambda)$.
    \begin{enumerate}
       \item Muestre que la distribución marginal de $y$ es:
$$
p(y) = \frac{\lambda}{(\lambda+1)^{y+1}}\,,\qquad y = 0,1,\ldots\qquad\lambda>0\,.
$$
\textbf{Desarrollo:}

veamos que si $y\mid x\sim\textsf{Poi}(x)$  entonces $p(y\mid x)=\frac{e^{-x}x^{y}}{y!}$  y $p(x)=\lambda e^{-\lambda x}$ así
$$ p(y) = \stackrel{\text{Definición}}{\int_{\Theta} p(y,\theta)d \theta }=\int_{0}^{\infty}p(y \mid x)p(x)dx=\int_{0}^{\infty}\frac{e^{-x}x^{y}}{y!}\lambda e^{-\lambda  x}dx= \frac{\lambda}{y!}\int_{0}^{\infty} x^{y}e^{-(\lambda+1)x}dx$$ ahora que la integral toma la forma de la función de distribución de una distribución gamma la integral de esta es 1  
$$ p(y)=\frac{\lambda}{y!} \frac{\Gamma (y+1)}{(\lambda +1)^{y+1}}  \stackrel{\text{Densidad distri Gamma =1}}{ \int_{0}^{\infty} \frac{(\lambda +1)^{y+1}}{\Gamma (y+1)} x^{(y+1)-1}e^{-(\lambda+1)x}dx}=\frac{\lambda}{y!} \frac{(y)!}{(\lambda +1)^{y+1}}=\frac{\lambda}{(\lambda +1)^{y+1}}
$$
\item Simule $N=100,000$ muestras independientes e idénticamente distribuidas de $y$ con $\lambda = 1$, y compare la distribución empírica correspondiente con la distribución exacta obtenida en el numeral anterior.
\end{enumerate}
\end{enumerate}

\textbf{Desarrollo:}

\begin{verbatim}
##   y     Sim        Exact         Diff
## ---  ------  -----------  -----------
##   0  0.5039  0.5          0.0039
##   1  0.2432  0.25         0.0068
##   2  0.123   0.125        0.002
##   3  0.0672  0.0625       0.0047
##   4  0.0312  0.03125      5e-05
##   5  0.0157  0.015625     7.5e-05
##   6  0.0082  0.0078125    0.0003875
##   7  0.0034  0.00390625   0.00050625
##   8  0.0017  0.00195312   0.000253125
##   9  0.0012  0.000976562  0.000223438
##  10  0.0005  0.000488281  1.17188e-05
##  11  0.0001  0.000244141  0.000144141
##  12  0.0005  0.00012207   0.00037793
##  13  0.0001  6.10352e-05  3.89648e-05
##  14  0.0001  3.05176e-05  6.94824e-05
\end{verbatim}

\begin{verbatim}
## <BarContainer object of 15 artists>
\end{verbatim}

\begin{verbatim}
## <BarContainer object of 15 artists>
\end{verbatim}

\begin{verbatim}
## (array([-2.,  0.,  2.,  4.,  6.,  8., 10., 12., 14., 16.]), [Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, '')])
\end{verbatim}

\includegraphics{Taller-2_files/figure-latex/sim2-1.pdf}

\begin{enumerate}
  \item[4.] Muestre que si $y\mid\theta$ tiene distribución exponencial con parámetro $\theta$, entonces la distribución $\textsf{Gamma}$ sirve como distribución previa conjugada para hacer inferencias sobre $\theta$, dada una muestra aleatoria de valores de $y$.
\end{enumerate}

\textbf{Desarrollo:}

Se tiene que \(y_i\mid \theta \stackrel{\text{iid}}{\sim} exp(\theta)\)
y la distribución previa \(\theta \sim Gamma(a,b)\) entonces
\[ p(y \mid \theta)=\theta e^{-\theta y} \quad \text{ y ademas} \quad p(\theta)=\frac{b^a}{\Gamma (a)}\theta^{a-1}e^{-b\theta}\]

así \(s=\sum_{i=1}^ny_i\) estadístico suficiente y la distribución a
posterior sera
\[p(\theta \mid \boldsymbol{y}) =  \stackrel{\text{T.Bayes}}{\frac{p(\boldsymbol{y}\mid \theta)p(\theta)}{p(\boldsymbol{y})}}\]
luego
\[p(\boldsymbol{y})=\int_\Theta p(\boldsymbol{y},\theta) d\theta = \int_\Theta p(\boldsymbol{y} \mid \theta )p(\theta)d\theta =\int_0 ^\infty \theta^n e^{-\sum y_i \theta}[\frac{b^a}{\Gamma (a)}\theta^{a-1}e^{-b\theta}]d\theta=\frac{b^a}{\Gamma (a)}\int_0 ^\infty \theta^{(a+n)-1}e^{-(b+s)\theta}d\theta\]\\
recordando la forma de la densidad de una distribución gamma completamos
de la siguiente forma:

\begin{align}
p(\boldsymbol{y})=& \frac{b^a}{\Gamma (a)}\int_0 ^\infty \theta^{(a+n)-1}e^{-(b+s)\theta}d\theta \\
                =& \frac{b^a}{\Gamma (a)}\frac{\Gamma (a+n) }{(b+s)^{(a+n)}} \stackrel{\text{Densidad Gamma}}{ \int_0 ^\infty \frac{(b+s)^{(a+n)}} {\Gamma (a+n) }\theta^{(a+n)-1}e^{-(b+s)\theta}d\theta }  \\
                =& \frac{b^a}{\Gamma (a)}\frac{\Gamma (a+n) }{(b+s)^{(a+n)}} 
\end{align}

luego usando el teorema de Bayes

\begin{align}
  p(\theta \mid \boldsymbol{y}) = & \stackrel{\text{T.Bayes}}{\frac{p(\boldsymbol{y}\mid \theta)p(\theta)}{p(\boldsymbol{y})}} \\
                              = &\frac{\theta^n e^{-s\theta}\frac{b^a}{\Gamma (a)}\theta^{a-1}e^{-b\theta}}{\frac{b^a}{\Gamma (a)}\frac{\Gamma (a+n) }{(b+s)^{(a+n)}} } \quad \text{cancelando}\\
                              =&\frac{(b+s)^{(a+n)}}{\Gamma (a+n) }\theta^{(a+n)-1} e^{-(b+s) \theta}\\
                              \theta \mid \boldsymbol{y} \sim Gamma(a+n,b+s.)
\end{align}

entonces la distribución \(\textsf{Gamma}\) sirve como distribución
previa conjugada para hacer inferencias sobre \(\theta\).

\begin{enumerate}
\item[5.]
Suponga que Su estado de información previo para $\theta$, la proporción de individuos que apoyan la pena de muerte en California, es Beta con media $E(\theta)$=0.6 y desviación estándar $DE(\theta)=0.3$.
  \begin{enumerate}
    \item Determine los hiperparámetros de Su distribución previa y dibuje la función de densidad correspondiente.
    
    \textbf{Desarrollo:} 
    
    Puesto que el estado de información previa se puede modelar a través de una función beta de parámetros a y b ,tendremos entonces que :
    
    \begin{equation*}
      E(\theta)=0.6 \Longrightarrow \frac{a}{a+b}=0.6 \Longrightarrow b=(2/3)a
    \end{equation*}
    de la misma manera
    \begin{align*}
        DE(\theta)&=(\frac{ab}{(a+b)^2(a+b+1)} )^{1/2} \Longrightarrow 0.09=\frac{ab}{(a+b)^2(a+b+1)}\\
                 0.09 &=\frac{(2/3)a^2}{(\frac{5}{3}a)^2(\frac{5}{3}a+1)}\\
               \frac{2}{3} &= (\frac{9}{100})(\frac{25}{9})(\frac{5}{3}a+1) \\
               \frac{8}{3} &=\frac{5}{3}a+1\\
               a&=1
    \end{align*}
    
    así $a=1$ y $b=2/3$ entonces el modelo será $Beta(1,\frac{2}{3})$
    

    
  \end{enumerate}
\end{enumerate}

\includegraphics{Taller-2_files/figure-latex/p5-3.pdf}

\begin{enumerate}
  \item[(b)] Se toma una muestra aleatoria de 1,000 californianos y el $65\%$ apoya la pena de muerte. Calcule tanto la media     como la desviación estándar posterior para $\theta$. Dibuje la función de densidad posterior correspondiente.
    
    \textbf{Solución:}
    
      Se tiene que la distribución muestral $s \mid \theta \sim binomial (n=1000,p=0.65)$ y $\theta\sim               beta(a=1,b=\frac{2}{3})$  por el modelo beta-binomial se tiene que la distribución posterior es $beta(1+650,1+350)$ donde $s=650$
      
    Además tenemos que el valor esperado es $E(s\mid \theta)= \frac{651}{651+351}=0.6497$  y la $Var(s\mid \theta)=\frac{(651)(351)}{(651+351)^2(651+351+1)}=0.0002269$ 
      
![](Taller-2_files/figure-latex/fig3-5.pdf)<!-- --> 
  
      
\end{enumerate}

\end{document}
